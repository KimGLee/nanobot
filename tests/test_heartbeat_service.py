import asyncio

import pytest

from nanobot.heartbeat.service import HeartbeatDecision, HeartbeatService
from nanobot.providers.base import LLMResponse, ToolCallRequest


class DummyProvider:
    def __init__(self, responses: list[LLMResponse]):
        self._responses = list(responses)

    async def chat(self, *args, **kwargs) -> LLMResponse:
        if self._responses:
            return self._responses.pop(0)
        return LLMResponse(content="", tool_calls=[])


@pytest.mark.asyncio
async def test_start_is_idempotent(tmp_path) -> None:
    provider = DummyProvider([])

    service = HeartbeatService(
        workspace=tmp_path,
        provider=provider,
        model="openai/gpt-4o-mini",
        interval_s=9999,
        enabled=True,
    )

    await service.start()
    first_task = service._task
    await service.start()

    assert service._task is first_task

    service.stop()
    await asyncio.sleep(0)


@pytest.mark.asyncio
async def test_decide_returns_skip_when_no_tool_call(tmp_path) -> None:
    provider = DummyProvider([LLMResponse(content="no tool call", tool_calls=[])])
    service = HeartbeatService(
        workspace=tmp_path,
        provider=provider,
        model="openai/gpt-4o-mini",
    )

    decision = await service._decide("heartbeat content")
    assert decision.action == "skip"
    assert decision.task_intent == ""
    assert decision.must_keep == []


@pytest.mark.asyncio
async def test_decide_prefers_task_intent_and_preserves_structured_fields(tmp_path) -> None:
    provider = DummyProvider([
        LLMResponse(
            content="",
            tool_calls=[
                ToolCallRequest(
                    id="hb_1",
                    name="heartbeat",
                    arguments={
                        "action": "run",
                        "tasks": "legacy summary",
                        "task_intent": "do full morning checks",
                        "must_keep": ["must include links", "before 09:30"],
                        "source_refs": ["L2-L4", "L8"],
                    },
                )
            ],
        )
    ])

    service = HeartbeatService(
        workspace=tmp_path,
        provider=provider,
        model="openai/gpt-4o-mini",
    )

    decision = await service._decide("heartbeat content")
    assert decision.action == "run"
    assert decision.task_intent == "do full morning checks"
    assert decision.must_keep == ["must include links", "before 09:30"]
    assert decision.source_refs == ["L2-L4", "L8"]


def test_build_execution_payload_prioritizes_constraints_and_refs(tmp_path) -> None:
    provider = DummyProvider([])
    service = HeartbeatService(
        workspace=tmp_path,
        provider=provider,
        model="openai/gpt-4o-mini",
    )

    content = "\n".join(
        [
            "# HEARTBEAT",
            "- [ ] check inbox",
            "- [ ] check calendar",
            "notes one",
            "notes two",
            "must include source links",
            "noise a",
            "Deadline: before 09:30",
        ]
        + [f"noise line {i}" for i in range(1, 120)]
    )

    payload = service._build_execution_payload(
        HeartbeatDecision(
            action="run",
            task_intent="run heartbeat",
            must_keep=["must include source links"],
            source_refs=["L2-L3", "L8"],
        ),
        content,
    )

    assert payload.summary == "run heartbeat"
    assert "- [ ] check inbox" in payload.selected_sections
    assert "- [ ] check calendar" in payload.selected_sections
    assert "must include source links" in payload.selected_sections
    assert "Deadline: before 09:30" in payload.selected_sections
    assert payload.dropped_non_empty_lines > 0

    rendered = service._render_execution_input(payload)
    assert "Use the following HEARTBEAT.md context" in rendered
    assert "Context truncated:" in rendered


@pytest.mark.asyncio
async def test_trigger_now_executes_with_prioritized_context_payload(tmp_path) -> None:
    (tmp_path / "HEARTBEAT.md").write_text(
        "\n".join(
            [
                "# HEARTBEAT",
                "- [ ] do thing",
                "must not message at night",
                "Deadline: before 09:30",
            ]
            + [f"filler {i}" for i in range(80)]
        ),
        encoding="utf-8",
    )

    provider = DummyProvider([
        LLMResponse(
            content="",
            tool_calls=[
                ToolCallRequest(
                    id="hb_1",
                    name="heartbeat",
                    arguments={
                        "action": "run",
                        "task_intent": "check open tasks",
                        "must_keep": ["must not message at night"],
                        "source_refs": ["L2-L4"],
                    },
                )
            ],
        )
    ])

    called_with: list[str] = []

    async def _on_execute(tasks: str) -> str:
        called_with.append(tasks)
        return "done"

    service = HeartbeatService(
        workspace=tmp_path,
        provider=provider,
        model="openai/gpt-4o-mini",
        on_execute=_on_execute,
    )

    result = await service.trigger_now()
    assert result == "done"
    assert len(called_with) == 1
    payload = called_with[0]
    assert "check open tasks" in payload
    assert "- [ ] do thing" in payload
    assert "must not message at night" in payload
    assert "Deadline: before 09:30" in payload


@pytest.mark.asyncio
async def test_trigger_now_returns_none_when_decision_is_skip(tmp_path) -> None:
    (tmp_path / "HEARTBEAT.md").write_text("- [ ] do thing", encoding="utf-8")

    provider = DummyProvider([
        LLMResponse(
            content="",
            tool_calls=[
                ToolCallRequest(
                    id="hb_1",
                    name="heartbeat",
                    arguments={"action": "skip"},
                )
            ],
        )
    ])

    async def _on_execute(tasks: str) -> str:
        return tasks

    service = HeartbeatService(
        workspace=tmp_path,
        provider=provider,
        model="openai/gpt-4o-mini",
        on_execute=_on_execute,
    )

    assert await service.trigger_now() is None
